{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('mnist_train.csv')\n",
    "# test_data = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "def load_hdf5_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        images = np.array(h5_file['image'])\n",
    "        images = torch.tensor(images)\n",
    "        labels = np.array(h5_file['label'])\n",
    "        labels = torch.tensor(labels)    \n",
    "    print(\"Images shape: \", images.shape) #, 'Images dtype: ', images.dtype)\n",
    "    print(\"Labels shape: \", labels.shape) #, 'Labels dtype: ', labels.dtype)\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_hdf5_data('Indian_dataset_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=0.2, random_state=0,stratify=labels)\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_1 = train_x[train_y==1]\n",
    "train_y_1 = train_y[train_y==1]\n",
    "train_x_0 = train_x[train_y==0]\n",
    "train_y_0 = train_y[train_y==0]\n",
    "\n",
    "test_x_1 = test_x[test_y==1]\n",
    "test_y_1 = test_y[test_y==1]\n",
    "test_x_0 = test_x[test_y==0]\n",
    "test_y_0 = test_y[test_y==0]\n",
    "\n",
    "train_y_1.shape,train_y_0.shape,test_y_1.shape,test_y_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 10 values from 0 to len(data_1_array)\n",
    "random_values = np.random.randint(0, len(train_x_1), 10)\n",
    "\n",
    "# train pool split\n",
    "train_1, train_1_y = train_x_1[random_values], train_y_1[random_values]\n",
    "pool_1, pool_1_y = np.delete(train_x_1, random_values, axis=0), np.delete(train_y_1, random_values, axis=0)\n",
    "\n",
    "# random 10 values from 0 to len(data_0_array)\n",
    "random_values = np.random.randint(0, len(train_x_0), 10)\n",
    "\n",
    "# train pool split\n",
    "train_0, train_0_y = train_x_0[random_values], train_y_0[random_values]\n",
    "pool_0, pool_0_y = np.delete(train_x_0, random_values, axis=0), np.delete(train_y_0, random_values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_1.shape, train_1.shape, pool_0.shape, train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = torch.cat((pool_1, pool_0), axis=0)\n",
    "pool_y = torch.cat((pool_1_y, pool_0_y), axis=0)\n",
    "\n",
    "pool.shape, pool_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    feature_dim = 8\n",
    "\n",
    "    def __init__(self,feature_dim=8,manual_seed=0):\n",
    "        super().__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        torch.manual_seed(manual_seed)\n",
    "        # print(\"Feature dim: \", self.feature_dim)\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5,stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5,stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, feature_dim, 5,stride=2)\n",
    "        self.fc1 = nn.Linear(feature_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def encoder(self,x):\n",
    "        # gives features \n",
    "        x = x.view(-1, 3, 256, 256)             # [20, 3, 256, 256]\n",
    "        x = self.pool(F.relu(self.conv1(x)))    # [20, 8, 63, 63]\n",
    "        x = self.pool(F.relu(self.conv2(x)))    # [20, 16, 15, 15]\n",
    "        x = self.pool(F.relu(self.conv3(x)))    # [20, 8, 3, 3]\n",
    "        x = self.pool(x)                        # [20, 8, 1, 1]\n",
    "        x = x.view(-1, self.feature_dim)             # [20, 8]\n",
    "        return x \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(self.fc1(x))                 # [20, 128]\n",
    "        x = F.relu(self.fc2(x))                 # [20, 64]\n",
    "        x = self.fc3(x)                         # [20, 1]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred,test_y):\n",
    "    true_positives = torch.sum(torch.logical_and(pred == 1, test_y == 1)).item()\n",
    "    true_negatives = torch.sum(torch.logical_and(pred == 0, test_y == 0)).item()\n",
    "    false_positives = torch.sum(torch.logical_and(pred == 1, test_y == 0)).item()\n",
    "    false_negatives = torch.sum(torch.logical_and(pred == 0, test_y == 1)).item()\n",
    "\n",
    "    accuracy = (true_positives, true_negatives, false_positives, false_negatives)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_X, train_y, epochs=100):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_X)\n",
    "        # output = torch.cat((1 - output, output), 1)\n",
    "        # print(output.shape, train_y.shape)\n",
    "        loss = criterion(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        pred = torch.round(output)\n",
    "        accuracy.append(metrics(pred,train_y))\n",
    "    \n",
    "    accuracy = np.array(accuracy)\n",
    "\n",
    "    return losses, accuracy, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, criterion, test_X, test_y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(test_X)\n",
    "        # output = torch.cat((1 - output, output), 1)\n",
    "        loss = criterion(output, test_y)\n",
    "        pred = torch.round(output)\n",
    "        accuracy = metrics(pred,test_y)\n",
    "        \n",
    "    return loss.item(), accuracy, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.cat((train_0, train_1), axis=0).float()\n",
    "train_y = torch.cat((train_0_y, train_1_y), axis=0).float()\n",
    "train_y = train_y.unsqueeze(1)\n",
    "# train_y = F.one_hot(train_y.to(torch.int64), num_classes=2).float()\n",
    "\n",
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracy, pred = train(model, optimizer, criterion, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(100*(accuracy[:, 0]+accuracy[:, 1])/(accuracy[:, 0]+accuracy[:, 1]+accuracy[:, 2]+accuracy[:, 3]))\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(model, train_x, pool_x, pool_y, ranks=False):\n",
    "    # features = model(train_x, features=True)\n",
    "    features = model.encoder(train_x)\n",
    "    centroid_feature = torch.mean(features, dim=0)\n",
    "    # pool_features = model(pool_x, features=True)\n",
    "    pool_features = model.encoder(pool_x)\n",
    "\n",
    "    distance = torch.cdist(pool_features, centroid_feature.reshape(1, -1))\n",
    "    \n",
    "    n_max_idx = torch.argmax(distance)\n",
    "\n",
    "    if ranks:\n",
    "        distance_ranks = torch.argsort(distance.reshape(-1))\n",
    "\n",
    "        return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx], distance_ranks.reshape(-1)\n",
    "    \n",
    "    return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx]\n",
    "\n",
    "\n",
    "def farthest(model, train_x, pool_x, pool_y, ranks=False):\n",
    "    # features = model(train_x, features=True)\n",
    "    features = model.encoder(train_x)\n",
    "    # pool_features = model(pool_x, features=True)\n",
    "    pool_features = model.encoder(pool_x)\n",
    "    distances = torch.cdist(pool_features, features)\n",
    "    farthest = torch.max(distances, dim=1)\n",
    "    n_max_idx = torch.argmax(farthest.values)\n",
    "\n",
    "    if ranks:\n",
    "        distance_ranks = torch.argsort(farthest.values)\n",
    "\n",
    "        return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx], distance_ranks.reshape(-1)\n",
    "    \n",
    "    return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx]\n",
    "\n",
    "\n",
    "def closest(model, train_x, pool_x, pool_y, ranks=False):\n",
    "    # features = model(train_x, features=True)\n",
    "    features = model.encoder(train_x)\n",
    "    # pool_features = model(pool_x, features=True)\n",
    "    pool_features = model.encoder(pool_x)\n",
    "    distances = torch.cdist(pool_features, features)\n",
    "    closest = torch.min(distances, dim=1)\n",
    "    n_max_idx = torch.argmax(closest.values)\n",
    "\n",
    "    if ranks:\n",
    "        distance_ranks = torch.argsort(closest.values)\n",
    "\n",
    "        return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx], distance_ranks.reshape(-1)\n",
    "    \n",
    "    return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx]\n",
    "\n",
    "\n",
    "def entropy(model, pool_x, pool_y, ranks=False):\n",
    "    p = model(pool_x)\n",
    "\n",
    "    entropy = torch.where((p == 0) | (p == 1), torch.zeros_like(p), -p*torch.log2(p) - (1-p)*torch.log2(1-p)).reshape(-1)\n",
    "\n",
    "    n_max_idx = torch.argmax(entropy)\n",
    "\n",
    "    if ranks:\n",
    "        entropy_ranks = torch.argsort(entropy)\n",
    "\n",
    "        return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx], entropy_ranks\n",
    "    \n",
    "    return n_max_idx, pool_x[n_max_idx], pool_y[n_max_idx]\n",
    "\n",
    "\n",
    "def compare_ranks(ranks1, ranks2):\n",
    "    added = ranks1.reshape(-1) + ranks2.reshape(-1)\n",
    "\n",
    "    min_rank, min_idx = torch.min(added, dim=0)\n",
    "\n",
    "    return min_rank, min_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test compare ranks\n",
    "ranks1 = torch.tensor([10, 2, 3, 4, 5])\n",
    "ranks2 = torch.tensor([5, 4, 3, 2, 1])\n",
    "\n",
    "compare_ranks(ranks1, ranks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion):\n",
    "    test_X = torch.cat((test_x_0, test_x_1), axis=0).float()\n",
    "    test_y = torch.cat((test_y_0, test_y_1), axis=0).float()\n",
    "    test_y = test_y.unsqueeze(1)\n",
    "    # test_y = F.one_hot(test_y.to(torch.int64), num_classes=2).float()\n",
    "\n",
    "    loss, acc, _ = eval(model, criterion, test_X, test_y)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.cat((train_0, train_1), axis=0).float()\n",
    "train_y = torch.cat((train_0_y, train_1_y), axis=0).float()\n",
    "train_y = train_y.unsqueeze(1)\n",
    "# train_y = F.one_hot(train_y.to(torch.int64), num_classes=2).float()\n",
    "\n",
    "pool_X = torch.cat((pool_0, pool_1), axis=0).float()\n",
    "pool_y = torch.cat((pool_0_y, pool_1_y), axis=0).float()\n",
    "pool_y = pool_y.unsqueeze(1)\n",
    "test_y = test_y.unsqueeze(1)\n",
    "# pool_y = F.one_hot(pool_y.to(torch.int64), num_classes=2).float()\n",
    "train_X.shape, train_y.shape, pool_X.shape, pool_y.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [[], [], []]\n",
    "accuracy = [[], [], []]\n",
    "ac_f = {1: centroid, 2: farthest, 3: closest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Active Learning Method: {i+1} ------------------------------\")\n",
    "    f = ac_f[i+1]\n",
    "\n",
    "    model = Model()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    t_x = deepcopy(train_X)\n",
    "    t_y = deepcopy(train_y)\n",
    "    p_x = deepcopy(pool_X)\n",
    "    p_y = deepcopy(pool_y)\n",
    "    \n",
    "    for j in trange(10):\n",
    "        _, _, _ = train(model, optimizer, criterion, t_x, t_y)\n",
    "        loss, acc = test(model, criterion)\n",
    "\n",
    "        losses[i].append(loss)\n",
    "        accuracy[i].append(100*(acc[0]+acc[1])/(acc[0] + acc[1] + acc[2] + acc[3]))\n",
    "\n",
    "        _, _, _, ranks1 = f(model, t_x, p_x, p_y, ranks=True)\n",
    "        _, _, _, ranks2 = entropy(model, p_x, p_y, ranks=True)\n",
    "\n",
    "        min_rank, ind = compare_ranks(ranks1, ranks2)\n",
    "\n",
    "        t_x = torch.cat((t_x, p_x[ind].reshape(-1, 256, 256,3)), dim=0)\n",
    "        t_y = torch.cat((t_y, p_y[ind].reshape(-1, 1)), dim=0)\n",
    "\n",
    "\n",
    "        p_x = torch.cat((p_x[:ind], p_x[ind+1:]), dim=0)\n",
    "        p_y = torch.cat((p_y[:ind], p_y[ind+1:]), dim=0)\n",
    "\n",
    "        # print(f\"Epoch {j+1} - Loss: {losses[i][-1]} - Accuracy: {accuracy[i][-1]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_losses = []\n",
    "random_accuracy = []\n",
    "manuel_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "for i in range(10):\n",
    "    torch.manual_seed(seed)\n",
    "    r_losses = []\n",
    "    r_accuracy = []\n",
    "    print(f\"Random {i+1} ------------------------------\")\n",
    "\n",
    "    model = Model(manual_seed=seed)\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    t_x = deepcopy(train_X)\n",
    "    t_y = deepcopy(train_y)\n",
    "    p_x = deepcopy(pool_X)\n",
    "    p_y = deepcopy(pool_y)\n",
    "\n",
    "    for j in trange(10):\n",
    "        _, _, _ = train(model, optimizer, criterion, t_x, t_y)\n",
    "        loss, acc = test(model, criterion)\n",
    "\n",
    "        r_losses.append(loss)\n",
    "        r_accuracy.append(100*(acc[0]+acc[1])/(acc[0] + acc[1] + acc[2] + acc[3]))\n",
    "        \n",
    "        ind = torch.randint(0, len(p_x),(1,)).item()\n",
    "\n",
    "        t_x = torch.cat((t_x, p_x[ind].reshape(-1, 256, 256,3)), dim=0)\n",
    "        t_y = torch.cat((t_y, p_y[ind].reshape(-1, 1)), dim=0)\n",
    "\n",
    "        p_x = torch.cat((p_x[:ind], p_x[ind+1:]), dim=0)\n",
    "        p_y = torch.cat((p_y[:ind], p_y[ind+1:]), dim=0)\n",
    "\n",
    "        # print(f\"Epoch {j+1} - Loss: {r_losses[-1]} - Accuracy: {r_accuracy[-1]}%\")\n",
    "\n",
    "    random_losses.append(r_losses)\n",
    "    random_accuracy.append(r_accuracy)\n",
    "    seed += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses[0], label=\"Centroid\")\n",
    "plt.plot(losses[1], label=\"Farthest\")\n",
    "plt.plot(losses[2], label=\"Closest\")\n",
    "plt.plot(np.mean(random_losses, axis=0), label=\"Random\")\n",
    "plt.fill_between(np.arange(10), np.mean(random_losses, axis=0) - 1.645*np.std(random_losses, axis=0), np.mean(random_losses, axis=0) + 1.645*np.std(random_losses, axis=0), alpha=0.3)\n",
    "plt.xlabel(\"No.of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over #iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.plot(random_losses[i], label=f\"Random {i+1}\")\n",
    "plt.xlabel(\"No.of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss over #iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(accuracy[0], label=\"Centroid\")\n",
    "plt.plot(accuracy[1], label=\"Farthest\")\n",
    "plt.plot(accuracy[2], label=\"Closest\")\n",
    "plt.plot(np.mean(random_accuracy, axis=0), label=\"Random\")\n",
    "plt.fill_between(np.arange(10), np.mean(random_accuracy, axis=0) - 1.645*np.std(random_accuracy, axis=0), np.mean(random_accuracy, axis=0) + 1.645*np.std(random_accuracy, axis=0), alpha=0.3)\n",
    "plt.xlabel(\"No.of Iterations\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(\"Test Accuracy over #iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.plot(random_accuracy[i], label=f\"Random {i+1}\")\n",
    "plt.xlabel(\"No.of Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Test Accuracy over #iterations\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing seed\n",
    "seed=0\n",
    "for i in range(2):\n",
    "    torch.manual_seed(seed)\n",
    "    for j in range(2):\n",
    "        ind = torch.randint(0, len(p_x),(1,)).item()\n",
    "        print(ind)\n",
    "    seed += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
